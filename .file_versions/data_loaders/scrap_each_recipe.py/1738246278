import io
import pandas as pd
import requests
from bs4 import BeautifulSoup
from tqdm import tqdm

if 'data_loader' not in globals():
    from mage_ai.data_preparation.decorators import data_loader
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


@data_loader
def load_data_from_api(liens, *args, **kwargs):
    """
    Fonction pour scraper les pages de recettes
    """
    print(len(liens))
    from tqdm import tqdm

    recipe_soup_list = []
    for url in tqdm(liens[-4:-1]):
        print(url)
        try:
            response_recipe = requests.get(url)
            recipe_soup = BeautifulSoup(response_recipe.content, "html.parser")
            recipe_soup_list.append(recipe_soup)
        except Exception:
            print(f"{url} was broken")
    print("caalarche")
    return recipe_soup_list
    recipe_soup_list = []
    for url in liens:
        try:
            # Ajouter un User-Agent pour éviter d'être bloqué
            response_recipe = requests.get(url)
            print("1")

            # Vérifier si la requête a réussi (code 200)
            if response_recipe.status_code == 200:
                recipe_soup = BeautifulSoup(response_recipe.content, "html.parser")
                recipe_soup_list.append(recipe_soup)
                print("2")
            else:
                print(f"Erreur {response_recipe.status_code} sur {url}")
                print("3")
        except Exception as e:
            print(f"Erreur lors de la requête pour {url}: {e}")
            print("4")
    print(len(recipe_soup_list))
    return recipe_soup_list  # Retourne la liste des pages scrapées
